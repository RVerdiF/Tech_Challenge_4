# Tech Challenge - Fase 4: PrevisÃ£o de PreÃ§os de AÃ§Ãµes com LSTM

Este projeto Ã© uma implementaÃ§Ã£o de um modelo de Deep Learning (LSTM) para prever o preÃ§o de fechamento de aÃ§Ãµes, com uma API para servir as previsÃµes.

## ğŸ“ DescriÃ§Ã£o

O objetivo deste desafio Ã© construir uma soluÃ§Ã£o completa de Machine Learning, desde a coleta de dados atÃ© o deploy de uma API. O modelo utiliza uma rede neural recorrente do tipo LSTM (Long Short-Term Memory) para prever o valor de fechamento de uma aÃ§Ã£o com base em seu histÃ³rico de preÃ§os.

A soluÃ§Ã£o inclui:
- Coleta de dados histÃ³ricos da aÃ§Ã£o PETR4.SA (Petrobras) via `yfinance`.
- PrÃ©-processamento e normalizaÃ§Ã£o dos dados.
- Treinamento de um modelo LSTM com TensorFlow/Keras.
- Uma API RESTful construÃ­da com FastAPI para servir as previsÃµes do modelo.
- Dockerfile para facilitar o deploy da aplicaÃ§Ã£o.

## ğŸ“‚ Estrutura do Projeto

```
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ payload.json
â”œâ”€â”€ source
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â”œâ”€â”€ PETR4.SA_processed.npz
â”‚   â”‚   â””â”€â”€ PETR4.SA_raw.csv
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â”œâ”€â”€ lstm_model.h5
â”‚   â”‚   â””â”€â”€ scaler.joblib
â”‚   â”œâ”€â”€ plan.md
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ src
â”‚       â”œâ”€â”€ data_processing.py
â”‚       â””â”€â”€ train.py
â””â”€â”€ test_api.py
```

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Python 3.9+
- `pip` e `venv`

### 1. ConfiguraÃ§Ã£o do Ambiente

Clone o repositÃ³rio e configure o ambiente virtual:

```bash
git clone <url-do-repositorio>
cd <nome-do-repositorio>
python -m venv .venv
source .venv/bin/activate  # No Windows: .venv\Scripts\activate
pip install -r source/requirements.txt
```

### 2. Coleta e Treinamento

Execute os scripts em ordem para baixar os dados, prÃ©-processÃ¡-los e treinar o modelo.

```bash
# 1. Baixar e processar os dados
python source/src/data_processing.py

# 2. Treinar o modelo LSTM
python source/src/train.py
```
ApÃ³s a execuÃ§Ã£o, o modelo (`lstm_model.h5`) e o normalizador (`scaler.joblib`) estarÃ£o salvos na pasta `source/models`.

### 3. Executando a API Localmente

Com o modelo treinado, inicie a API FastAPI:

```bash
python source/main.py
```
A API estarÃ¡ disponÃ­vel em `http://127.0.0.1:8000`. VocÃª pode acessar a documentaÃ§Ã£o interativa em `http://127.0.0.1:8000/docs`.

### 4. Testando a API

Para fazer uma previsÃ£o, envie uma requisiÃ§Ã£o POST para o endpoint `/predict` com um histÃ³rico de 60 preÃ§os de fechamento.

VocÃª pode usar o script `test_api.py` para isso:
```bash
python test_api.py
```

Ou usar uma ferramenta como o `curl`:
```bash
curl -X POST "http://127.0.0.1:8000/predict" \
-H "Content-Type: application/json" \
-d 
  "history": [
    20.5, 21.2, 20.8, 22.1, 21.9, 20.5, 21.2, 20.8, 22.1, 21.9,
    20.5, 21.2, 20.8, 22.1, 21.9, 20.5, 21.2, 20.8, 22.1, 21.9,
    20.5, 21.2, 20.8, 22.1, 21.9, 20.5, 21.2, 20.8, 22.1, 21.9,
    20.5, 21.2, 20.8, 22.1, 21.9, 20.5, 21.2, 20.8, 22.1, 21.9,
    20.5, 21.2, 20.8, 22.1, 21.9, 20.5, 21.2, 20.8, 22.1, 21.9,
    20.5, 21.2, 20.8, 22.1, 21.9, 20.5, 21.2, 20.8, 22.1, 21.9
  ]
}"
```

## ğŸ³ Docker

Para construir e executar a aplicaÃ§Ã£o com Docker:

```bash
# 1. Construir a imagem Docker
docker build -t stock-predictor-api .

# 2. Executar o contÃªiner
docker run -d -p 8000:8000 --name stock-api stock-predictor-api
```
A API estarÃ¡ acessÃ­vel da mesma forma, em `http://localhost:8000`.

## 7. Monitoramento e Observabilidade

Para garantir a confiabilidade e o desempenho da API em produÃ§Ã£o, foi planejado um sistema de monitoramento baseado em mÃ©tricas e logs.

### Logging

A aplicaÃ§Ã£o implementa logs bÃ¡sicos via saÃ­da padrÃ£o (stdout), o que Ã© ideal para ambientes containerizados.
- **O que Ã© logado:** Erros crÃ­ticos de carregamento de modelo (`RuntimeError`), exceÃ§Ãµes durante a prediÃ§Ã£o e erros de validaÃ§Ã£o.
- **Coleta:** Em produÃ§Ã£o, esses logs devem ser capturados pelo driver de log do Docker e encaminhados para um agregador como ELK Stack (Elasticsearch, Logstash, Kibana) ou AWS CloudWatch.

### Plano de MÃ©tricas (Prometheus + Grafana)

Para monitoramento de performance e saÃºde da aplicaÃ§Ã£o, o plano de arquitetura recomenda:

1.  **InstrumentaÃ§Ã£o da API:**
    Utilizar a biblioteca `prometheus-fastapi-instrumentator` para expor mÃ©tricas automÃ¡ticas.
    *   *AlteraÃ§Ã£o necessÃ¡ria no `main.py`:*
        ```python
        from prometheus_fastapi_instrumentator import Instrumentator
        
        # ApÃ³s criar a app
        Instrumentator().instrument(app).expose(app)
        ```

2.  **Coleta de MÃ©tricas (Prometheus):**
    Configurar um serviÃ§o Prometheus para realizar o *scrape* do endpoint `/metrics` da API a cada 15-30 segundos.

3.  **VisualizaÃ§Ã£o (Grafana):**
    Criar dashboards no Grafana conectados ao Prometheus para monitorar:
    *   **LatÃªncia:** Tempo de resposta do endpoint `/predict`.
    *   **TrÃ¡fego:** NÃºmero de requisiÃ§Ãµes por minuto (RPM).
    *   **Erros:** Taxa de respostas 4xx/5xx.
    *   **Recursos:** Uso de CPU e MemÃ³ria do container.
